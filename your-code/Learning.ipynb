{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Analysis\n",
    "\n",
    "\n",
    "Lesson Goals\n",
    "\n",
    "    Introduce survival analysis\n",
    "    Introduce Kaplan-Meier estimates\n",
    "    Perform survival analysis on event data\n",
    "    Visualize and compare survival curves\n",
    "    Perform survival analysis for cohorts from different perspectives\n",
    "\n",
    "Introduction\n",
    "\n",
    "Survival analysis is an important topic in analytics that rarely receives the coverage it deserves. As the name implies, it was originally developed to quantify and measure the lifespans of individuals (how likely someone was to die or survive). For example, if you wanted to know what the probability of death over time was for a certain a group of people who had contracted some illness, you would use survival analysis. However, the techniques used in survival analysis can be applied to a wide variety of situations.\n",
    "\n",
    "In this lesson, we are going to cover the basics of survival analysis so that you can leverage this valuable set of techniques in analyses that you conduct going forward. To do this, we will need to install a new Python library called lifelines that is specifically used for conducting survival analysis.\n",
    "\n",
    "$ pip install lifelines\n",
    "\n",
    "We will import the components of lifelines a little later as we need them. We are also going to be using Pandas in this lesson as well as Plotly and Cufflinks, so let's go ahead and import those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47dd8db4a3cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcufflinks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgo_offline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Analysis\n",
    "\n",
    "Survival analysis can be performed on various scenarios:\n",
    "\n",
    "    Estimating human lifespans\n",
    "    Estimating mechanical failures over time\n",
    "    Estimating length of customer retention\n",
    "    Estimating time to recovery for illnesses\n",
    "\n",
    "There are certain requirements for conducting a survival analysis. The first of these is that you need to have a field in your data that represents the occurrence (or lack thereof) of an event.\n",
    "\n",
    "The second requirement is that you need to have a field that represents the passage of time in some fashion. This can be datetimes or it can be a number that increases with the passage of time, such as number of days/weeks/months/years, the number of uses, distance traveled, etc.\n",
    "\n",
    "The third and final requirement is that you need to have at least one field to group by. Survival analysis calculates the survival rates for groups that something in common. The group by field is the thing they have in common. If you have multiple fields you can group by, you can perform the analysis for the groups represented by each field individually or you can combine them into more granular segments and examine the survival rates of those. However, you can only do this up to a point where the number of examples in a group become too few to reliably calculate their survival rates. So you need to balance the ability drill down into granular details with the need to have large enough groups to calculate meaningful and reliable survival rates.\n",
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "The data we will be working with in this lesson will be the customer churn data set from previous lessons. This data meets all three of our criteria above. It contains an event field (ChurnBinary) that indicates whether or not a customer has churned. It contains a field that represents the passage of time (tenure). And finally, it contains several categorical fields by which we can group customers so that we can explore their retention rates from different perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/churn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a Survival Analysis\n",
    "\n",
    "Now that we have identified the data we want to use and the corresponding fields, we can begin our analysis. The objective of our analysis is going to be to get a sense of the decline in customer retention rates as tenure increases among the different groups of customers we have in our data set.\n",
    "\n",
    "The easiest way to do this in Python is with the lifelines library. We are going to import the KaplanMeierFitter from lifelines. Kaplain-Meier curves are one of the most common statistical techniques used in survival analysis, and they will help us estimate the survival function of the different cohorts we designate (e.g. males vs. females, senior citizens vs. non-seniors, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, we are going to define a survival function that is going to accept a data frame and then specify each of the three necessary components for conducting a survival analysis (a group field, a time field, and an event field). Within the function, we are going to define our model and then create an empty list in which we are going to store our results. From there, we loop through the each of the unique values in the group field, grab the data in the time and event fields, fit our model to the data, and append the survival function results to our results list. At the end, we concatenate the data for each unique group field value together and then return those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survival(data, group_field, time_field, event_field):\n",
    "    model = KaplanMeierFitter()\n",
    "    results = []\n",
    "    \n",
    "    for i in data[group_field].unique():\n",
    "        group = data[data[group_field]==i]\n",
    "        T = group[time_field]\n",
    "        E = group[event_field]\n",
    "        model.fit(T, E, label=str(i))\n",
    "        results.append(model.survival_function_)\n",
    "    \n",
    "    survival = pd.concat(results, axis=1)\n",
    "    return survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this function, it is relatively easy to generate survival curves for any of the cohorts in our data set. For example, if we wanted to visualize retention rates over time by gender, we could do that with just a couple lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = survival(data, 'gender', 'tenure', 'ChurnBinary')\n",
    "\n",
    "rates.iplot(kind='line', xTitle='Tenure (Months)', yTitle='Retention Rate',\n",
    "            title='Retention Rates by Tenure and Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at tenure 0, both survival curves start at 1 (100%). The female curve then declines a little faster than the male curve and then they both continue to decline gradually until they get past 60 months, at which point the male curve takes a steeper dive below the female retention rates. Both curves end at around the 60% mark, meaning that after 70 months of tenure, a customer is approximately 40% likely to churn (60% retention rate).\n",
    "\n",
    "Using our function, we can easily swap out group fields to take a look at survival rates form different perspectives. Here are the survival curves for senior citizens and non-seniors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = survival(data, 'SeniorCitizen', 'tenure', 'ChurnBinary')\n",
    "\n",
    "rates.iplot(kind='line', xTitle='Tenure (Months)', yTitle='Retention Rate',\n",
    "            title='Retention Rates by Tenure and Senior Citizen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this perspective, we can see that the survival curve for senior citizens has a steeper slope than the curve for non-seniors, which causes them to end up with a much lower retention rate than non-seniors.\n",
    "\n",
    "What if we define our cohorts around the type of Internet service the customer has as opposed to demographics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = survival(data, 'InternetService', 'tenure', 'ChurnBinary')\n",
    "\n",
    "rates.iplot(kind='line', xTitle='Tenure (Months)', yTitle='Retention Rate',\n",
    "            title='Retention Rates by Tenure and Internet Service')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this perspective, we can see that customers without Internet service tend to have higher retention rates than ones who do. Among the ones that do have Internet service with the company, the ones that have DSL have much higher retention rates compared to the ones that have fiber optic, perhaps because the latter tends to be significantly more expensive.\n",
    "\n",
    "The company also provides customers with the option of signing up for one year or two year contracts as opposed to just paying for their services month-to-month. Let's see how the survival curves look for each of those three options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = survival(data, 'Contract', 'tenure', 'ChurnBinary')\n",
    "\n",
    "rates.iplot(kind='line', xTitle='Tenure (Months)', yTitle='Retention Rate',\n",
    "            title='Retention Rates by Tenure and Senior Citizen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably expected, the customers on two year contracts have the highest retention rates, even well past the 24 month (2 year) mark. Customers on one year contracts have high retention rates until about 40 months out, and then the rate at which they churn increases. And finally, the customers who pay month-to-month start churning almost right away with a very steep decline in retention between 0 and 10 months and then leveling off slightly but still pretty steep.\n",
    "\n",
    "\n",
    "\n",
    "# Usefulness of Survival Analysis\n",
    "\n",
    "As we saw above, survival analysis is useful for deriving insights about what factors matter most when you have event data over time. In our case, we were able to observe the survival curves estimating what percentage of customers the company would retain and what percentage are likely to churn over time from varying perspectives.\n",
    "\n",
    "This is useful to companies, as it allows them estimate when a customer is most likely to cancel their service. The company could then determine the appropriate time to intervene and offer the customer either a discounted upgrade or a lower price on the service they currently have (perhaps tied to a one or two year contract) to prevent them from leaving and thus increasing their retention rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
